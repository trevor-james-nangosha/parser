/**
 * Tokeniser class: responsible for pulling tokens from the stream generated by the parser.
 */
class Tokeniser {
    /**
     * the string gets passed into this function so that a stream of tokens is generated.
     * @param string
     */
    init(string) {
        this._string = string
        this._cursor = 0
    }

    /**
     * this function checks whether the cursor has reached the end of the file.
     * @returns 
     */
    isEOF() {
        return this._cursor === this._string.length
    }

    /**
     * this checks whether there are more tokens in the stream generated before the cursor can be moved.
     * @returns 
     */
    hasMoreTokens() {
        return this._cursor < this._string.length
    }

    /**
     * this returns the next token in the stream. If there is no token, it returns null
     * @returns 
     */
    getNextToken() {
        if (!this.hasMoreTokens()) {
            return null
        }

        const string = this._string.slice(this._cursor)
        let matched = /^\d+/.exec(string)
        if (matched !== null) {
            this._cursor += matched[0].length
            return {
                type: 'NUMBER',
                value: matched[0],
            }
        }


        //String tokens
        matched = /"[^"]*"/.exec(string);
        if (matched !== null) {
            this._cursor += matched[0].length
            return {
                type: 'STRING',
                value: matched[0]
            }
        }

        return null
    }
}

module.exports = {
    Tokeniser,
}